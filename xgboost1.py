# -*- coding: utf-8 -*-
"""xgboost1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YPc0ZvUbABZqM052sZxuIgw4c_haS93Y

[XGBOOST TUTORIAL](https://machinelearningmastery.com/develop-first-xgboost-model-python-scikit-learn/)

XGBOOST WITH TRAIN/TEST

XGBOOST WITH CV

XGBOOST WITH FEATURE SELECTION

[XGBOOST HYPERPAR TUNNING](https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/)

[tunning](https://blog.cambridgespark.com/hyperparameter-tuning-in-xgboost-4ff9100a3b2f)
"""

import time
import numpy as np
import xgboost as xgb
#from numpy import asarray
from sklearn import model_selection
import pandas as pd #import pandas
from numpy import sort
#from hummingbird.ml import convert
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split, RepeatedKFold
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score
from sklearn.model_selection import cross_val_score
from sklearn.feature_selection import SelectFromModel
from xgboost import plot_importance
from matplotlib import pyplot
from sklearn.metrics import  auc, confusion_matrix, f1_score, mean_squared_error, plot_confusion_matrix
from sklearn.metrics import  roc_auc_score, roc_curve, classification_report
from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score

from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv('/content/drive/MyDrive/breast-cancer-wisconsin.data.txt')
df.replace('?',-99999, inplace=True)
df.drop(['id'], 1, inplace=True)
X = np.array(df.drop(['class'], 1))
y = np.array(df['class'])
X = X.astype('float32')
y = LabelEncoder().fit_transform(y)
# Look at the dataset again
print(f'Number of Rows: {df.shape[0]}')
print(f'Number of Columns: {df.shape[1]}')
print(df.head())

"""# TRAIN/TEST SPLIT"""

# split data into train and test sets
seed = 42
test_size = 0.2
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=test_size, random_state=seed)
# fit model no training data
model = XGBClassifier()
model.fit(X_train, y_train)
# make predictions for test data
y_pred = model.predict(X_test)
predictions = [round(value) for value in y_pred]
# evaluate predictions
accuracy = accuracy_score(y_test, predictions)
print("Accuracy: %.2f%%" % (accuracy * 100.0))

recall = recall_score(y_test, y_pred, average="macro")
precision = precision_score(y_test, y_pred, average="macro", zero_division=0)
mse = mean_squared_error(y_test, y_pred)
f1score = f1_score(y_test, y_pred, average='weighted')
report = classification_report(y_test, y_pred)
print(">>> Metrics")
print(" Recall   : %.2f%%" % (recall * 100.0))
print("Precision :%.2f%%" % (precision * 100.0))
print("MSE    :%.2f%%" % (mse * 100.0))
print("F1 Score  :%.2f%%" % (f1score * 100.0))
print(report)

"""# CROSS VALIDATION"""

cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)
scoring = {'accuracy' : make_scorer(accuracy_score), 'precision' : make_scorer(precision_score),  'recall' : make_scorer(recall_score),  'f1_score' : make_scorer(f1_score)}
results = model_selection.cross_validate(model, X, y, cv=cv, scoring=scoring)
print("Cross validation score: {0:.2%} (+/- {1:.2%})".format(np.mean(results['test_accuracy']), np.std(results['test_accuracy'])*2))
print("precision score: {0:.2%} (+/- {1:.2%})".format(np.mean(results['test_precision']), np.std(results['test_precision'])*2))
print("recall score: {0:.2%} (+/- {1:.2%})".format(np.mean(results['test_recall']), np.std(results['test_recall'])*2))
print("f1_score: {0:.2%} (+/- {1:.2%})".format(np.mean(results['test_f1_score']), np.std(results['test_f1_score'])*2))

# plot feature importance
plot_importance(model)
pyplot.show()

"""# TRAIN SELECTED FEATURES"""

thresholds = sort(model.feature_importances_)
for thresh in thresholds:
  # select features using threshold
  selection = SelectFromModel(model, threshold=thresh, prefit=True)
  select_X_train = selection.transform(X_train)
  # train model
  selection_model = XGBClassifier()
  selection_model.fit(select_X_train, y_train)
  # eval model
  select_X_test = selection.transform(X_test)
  y_pred = selection_model.predict(select_X_test)
  predictions = [round(value) for value in y_pred]
  accuracy = accuracy_score(y_test, predictions)
  print("Thresh=%.3f, n=%d, Accuracy: %.2f%%" % (thresh, select_X_train.shape[1], accuracy*100.0))